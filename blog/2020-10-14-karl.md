---
layout: post
title: "KAR$^3$L Progress Update, October 2020"
author: "Shi Feng"
---

<head>
  <meta charset="utf-8">
  <script src="https://cdn.jsdelivr.net/npm/vega@5"></script>
	<script src="https://cdn.jsdelivr.net/npm/vega-lite@4"></script>
	<script src="https://cdn.jsdelivr.net/npm/vega-embed@6"></script>
</head>

[KAR$^3$L](http://karl.qanta.org/) is a next-generation spaced repetition learning tool developed by the natural language processing lab at University of Maryland ([CLIP lab](https://wiki.umiacs.umd.edu/clip/index.php/Main_Page)). Unlike traditional methods where all flashcards are treated as equal and all users are treated as equal, KAR$^3$L reads the content of each flashcard and the study history of each individual user, then chooses a time to review the flashcard in order to mxaimizes the psychological spacing effect.

In this post, we summarize our first phase tests. By analyzing the study history of our users, we provide some insights into how KAR$^3$L works, its advantages over traditional methods, and where it can be improved. We'll also give a sneak peek of what's coming next.

We are happy to discuss this project. Joining our [Discord](https://discord.com/invite/PTfEmHd), or reach out to our team directly: [@ihsgnef](https://twitter.com/ihsgnef), [@matthewmshu](https://twitter.com/@matthewmshu), and [feet-thinking@googlegroups.com](feet-thinking@googlegroups.com).

## Where we are right now?
Since our [public launch](https://hsquizbowl.org/forums/viewtopic.php?f=123&p=379140&sid=8ae602e914bc1e56736a07030176c718) on August 24th, 424 users signed up, and produced in total over 75,000 study records. Each study record consists of the user ID, flashcard ID, date of study, and whether the user answered correctly. The growth in number of users and records is shown below.

<div id="vis1"></div>

In addition to developing a new tool for studying, we also want to answer the scientific question of whether machine learning can improve spaced repetition. For this purpose, we implemented two traditional models: [Leitner](https://en.wikipedia.org/wiki/Leitner_system) and [SM-2](https://en.wikipedia.org/wiki/SuperMemo), and compare them against our model. Some users who signed up are randomly selected to these traditional methods as control groups. Below is a breakdown of how many users are assigned to each model, and how many records each group contributed.

(plot of accumulative number of studies with breakdown by repetition model, takeaway?)

## Overview of KAR$^3$L vs. Leitner vs. SM-2
Now we take a closer look at how our model performs. First, we want to get a basic understanding of what kind of flashcards are shown to the users. We categorize each study record by both the result (corret or wrong) and whether the flashcard shown is new. This gives us an rough idea of how each model handles the trade-off between showing new flashcards versus reviewing old ones, and how the users respond to them (successful or failed recall). The figure belows visualizes this breakdown of study records in to these $2\times2=4$ categories, and how this breakdown changes as the users spend more time studying. 

<div id="vis2"></div>

We start to see some difference between KAR$^3$L and other models. In particular, KAR$^3$L is showing a higher ratio of new facts (light and dark red) than Leitner and SM-2, but the ratio of successful reviews (dark blue) is increasing at a slower pace than Leitner. But do these differences make KAR$^3$L better (or worse) at helping users make progress? To answer this question, we first need to come up with some metrics to gauge both the progress and the effort from each user.

## Progress vs. Effort

Our metric for progress is inspired by Ebbinghaus' notion of "first successful reproduction", Leitner's boxes, and the [progress graphs](https://ankiweb.net/shared/info/266436365) of [Anki](https://apps.ankiweb.net/).

Progress is made when a user correctly recalls a flashcard. However, not all correct recalls are equally indicative of the user's progress. For example, the first successful recall of a flashcard is more "valuable" than the recall of a card that the user is already familiar with. We use the notion of __levels__ to quantify how familiar each flashcard is to the user, based on past evaluation: a Level.$X$ flashcard is one that the user has correctly recall $x$ times in a row. We label new flashcards (not seen before) as "Initial" to differentiate them from Level.0 flashcards---old ones whose latest evaluation was unsuccessful. With lines visualizing the cumulative counts of both successful and failed recalls, we can see how the user progresses on each level as days go by. In the graph below, we can also see how the progress is contrasted with the user's effort on each day.

<div id="vis3"></div>

A view of this data that is more informative for us model developers is perhaps to look at the ratio of successful/total evaluations on each level:

<div id="vis4"></div>

Now, what would this plot look like if we had the perfect model? Well, we might want the "Initial" (blue) line to be lower, since currently more than 50% of the flashcards shown to this user are already known prior to study. We might want the Level.1-3 lines to be lower and closer to 50%, because according to Ebbinghaus each repetition boost the memory strength by 50%, so to maximize the gain each review should happen when the recall rate is about 50%; now it's at 80% for higher level facts.

To compare KAR$^3$L against Leitner and SM-2, we repeat the two figures about but in addition aggregate users assigned to each scheduler, and make x-axis represent number of minutes the user spent on the app.

<div id="vis5"></div>
<div id="vis6"></div>

## How does the model predict difficulty?

## Next Steps

<script type="text/javascript">
  vegaEmbed('#vis1', "https://raw.githubusercontent.com/ihsgnef/ihsgnef.github.io/master/images/n_users_and_n_records.json").catch(console.error);
  vegaEmbed('#vis2', "https://raw.githubusercontent.com/ihsgnef/ihsgnef.github.io/master/images/new_old_correct_wrong.json").catch(console.error);
  vegaEmbed('#vis3', "https://raw.githubusercontent.com/ihsgnef/ihsgnef.github.io/master/images/463_user_level_vs_effort.json").catch(console.error);
  vegaEmbed('#vis4', "https://raw.githubusercontent.com/ihsgnef/ihsgnef.github.io/master/images/463_user_level_ratio.json").catch(console.error);
  vegaEmbed('#vis5', "https://raw.githubusercontent.com/ihsgnef/ihsgnef.github.io/master/images/repetition_model_level_vs_effort.json").catch(console.error);
  vegaEmbed('#vis6', "https://raw.githubusercontent.com/ihsgnef/ihsgnef.github.io/master/images/repetition_model_level_ratio.json").catch(console.error);
</script>